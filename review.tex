\section{Literature Review}
This section overview of the basic concept of Dirichlet Process, including the representation, the main application-Dirichlet Process Mixture Model and the inference methods.  
\newcommand{\argmax}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{max}}\;}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{min}}\;}
\subsection{Background}
Large Data sets are often heterogeneous, cased b amalgams from underlying sub-populations. When doing analysis on such data sets, it often involves grouping the data to make the original data more heterogeneous. Traditionally, parametric models using a fixed and finite number of parameters could be used, but they suffer from over- or under-fitting of data when there is a misfit between the complexity of the model and the amount of data available. Thus, model complexity selection is often an important issue in parametric modeling. But whether we use cross validation or marginal probabilities as the basis for selection, model selection is an operation that is fraught with difficulties, especially when the data set grows larger and larger. 

The Bayesian Nonparametric approach is an alternative to parametric modeling and selection. Under this scheme, the model comes with an unbounded complexity, and under-fitting and over-fitting are mitigated. Typically, we assume that the observed data set $x_1,x_2,\cdots,x_i$ are i.i.d(Independent Identical Distributed) sampled from some underlying unknown distribution $\mathbb{F}$. In Bayesian approach,  a prior is placed over $\mathbb{F}$ then he posterior over  $\mathbb{F}$ given data is computed. This prior over distributions is given by a parametric family. But constraining distributions to lie within parametric families limits the scope and type of inferences that can be made. Instead, the nonparametric approach used a prior over distributions with wide support, typically the support being the space of all distributions.  The Dirichlet Process is currently one of the most popular Bayesian Nonparametric Models. It was first formalized in [1] for general Bayesian statistical modeling.,as a prior over distributions with wide support yet tractable posteriors. But the Dirichlet Process is limited by the fact that draws from it are often discrete distributions, and tractable posterior is hard to obtian when it generalized to more general non-conjugate priors until MCMC techniques became available in the area. 
\subsection{Dirichlet Process}
\subsubsection{Dirichlet Distribution}
A Dirichlet distribution is defined on the $\mathit{(k-1)}$-dimensional probability simplex, whic is a surface in $\mathbb{R}^k$ denoted by $\Delta_k
$ and defined to be the set of vectors whose $k$ components are non-negative and sum to 1, that is
\begin{equation}
	\Delta_k=\{q\in \mathbb{R}^k|\sum\nolimits_{i=1}^{k}q_i=1,q_i\geq 0\ for\ i=1,2,\cdots,k\}
\end{equation}
While the set $\Delta_k$ lies in a $k$-dimensional space, $\Delta_k$ is itself a $(k-1)$-dimensional object. Each point $q$ in the simplex can be thought of as a probability mass function(pmf) in its own right. The Dirichlet distribution can be thought of as a probability distribution over the $k-1$-dimensional probability simplex $\Delta_k$; that is, as a distribution over pmfs of length $k$.


\textbf{Dirichlet Distribution}: Let $Q=[Q_1,Q_2,\cdots,Q_k]$ be a random pmf, i.e. $Q_i\geq 0$ for $i=1,2,\cdots,k$ and $\sum\nolimits_{i=1}{k}Q_i=1$. In addition, suppose that $\alpha=[\alpha_1,\alpha_2,\cdots,\alpha_k]$ with $\alpha_i>0$ for each $i$, and let $\alpha_0=\sum\nolimits_{i=1^k\alpha_i}$. Then $Q$ is said to have a Dirichlet distribution with parameter $\alpha$, which we denote by $Q\sim Dir(\alpha)$, if it has $f(a;\alpha)=0$ then $q$ is not a pmf, else if $q$ is a pmf then
\begin{equation}
	f(q;\alpha)=\frac{\Gamma(\alpha_0)}{\prod\nolimits_{i=1}^{k}\Gamma(\alpha_i)}\prod_{i=1}^{k}q_i^{\alpha_i-1}
\end{equation}
where $\Gamma(s)$ denotes the gamma function, a generalization of the factorial function, for $s>0, \Gamma(s+1)=s\Gamma(s)$, and for positive integers $n$, $\Gamma(n)=(n-1)!, \Gamma(1)=1$. 
\begin{figure}[tbph!]
	\centering
	\includegraphics[width=\linewidth]{DirDis}
	\caption{Dirichlet distribution density plots(blue=low, red=high) over the probability simplex in $\mathbb{R}^3$ for various values of the parameter $\alpha$}
	\label{fig:DirDis}
\end{figure}
Fig. \ref{fig:DirDis} shows the plots of the density fo the Dirichlet distribution over the two-dimensional probability simplex for $k=3$ events lying in three-dimensional Euclidean space over a variety of parameter vector $\alpha$. When $\alpha=[1,1,1]$, the Dirichlet distribution reduces to uniform distribution over the simplex. When all the components of $\alpha$ satisfy $\alpha_i>1$, the density is monomodal with its mode somewhere in the interior of the simplex. And when $\alpha_i<1$, the plots has sharp peaks at the vertices of the simplex. Another important feature should be mentioned, as can be seen from the definition of Dirichlet distribution, is that the support is open thus does not include the vertices or edge of the simplex, which in reality means that no component of a pmf drawn from a Dirichlet will ever be zero.  Fig. \ref{fig:DPsample} shows plots of samples drawn i.i.d from different Dirichlet distributions.

\begin{figure}[tbph!]
	\centering
	\includegraphics[width=\linewidth]{DPsample}
	\caption{Plots of sample pmfs drawn from Dirichlet distributions over the probability simplex in $\mathbb{R}^3$ for various values of parameter $\alpha$}
	\label{fig:DPsample}
\end{figure}
\subsubsection{Dirichlet Process}
A Dirichlet Process is a distribution over probability distributions. Suppose that $\mathit{G}$ is a probability distribution over a measurable space $\Theta$, then  $\mathit{G}$ is a probability distribution over $\Theta$ and a DP is a distribution over all such distributions. A DP is parameterized b a concentration parameter $\alpha$ and a base measure(base distribution) $\mathit{H}$. So, the formal definition of a DP would be
\begin{equation}
	G\sim  DP(\alpha,\mathit{H})
\end{equation}
it means for a finite set of measurable paritions $A_1\cup\cdots\cup A_k=\Theta$, 
\begin{equation}
	(G(A_1)\cdots,G(A_k))\sim Dir(\alpha H(A_1),\cdots,\alpha H(A_k))
\end{equation}
which means the probabilities that  $\mathit{G}$ assigns to any finite
partition of  $\Theta$ follow a Dirichlet distribution  with parameters
$(\alpha H(A_1),\cdots,\alpha H(A_k))$.

Since $G$ is a random distribution we can inturn draw samples from $G$ itself. Let $\theta_1,\theta_2,\cdots,\theta_n$ be a sequence of independent draws from $G$. What is the posterior distribution of $G$ given observed values of $\theta_1,\theta_2,\cdots,\theta_n$. In other words, what is the posterior predictive distribution for a new item $p(\theta_{N+1}|\theta_1,\theta_2,\cdots,\theta_n)=\int p(\theta_{N+1}|G)p(G|\theta_1,\theta_2,\cdots,\theta_n)dG$? It is shown in ... that 
\begin{equation}
	(G(A_1),\cdots,G(A_k))|(\theta_1,\theta_2,\cdots,\theta_n)\sim Dir((\alpha H(A_1)+n_1,\cdots,\alpha H(A_k)+n_k)
\end{equation}
where $n_k=\#\{i:\theta_i\in A_k\}$ is the number of observed values in $A_k$. Rewriting the posterior DP, we have:
\begin{equation}
	G|(\theta_1,\theta_2,\cdots,\theta_n)\sim DP(\alpha+n,\frac{\alpha}{\alpha+n}H+\frac{n}{\alpha+n}\frac{\sum\nolimits_{i=1}^{n}\delta(\theta_i)}{n})
\end{equation}
and for the posterior distribution,
\begin{equation}
	\begin{split}
		p(\theta_{N+1}|\theta_1,\theta_2,\cdots,\theta_n)&= E[G(A)|\theta_1,\theta_2,\cdots,\theta_n] \\
		&=\frac{1}{\alpha+n}\left(\alpha H+\sum\limits_{i=1}^{n}\delta_{\theta_i}\right)
	\end{split}\label{eqa:dppos}
\end{equation}
Therefore the posterior base distribution given $\theta_1,\theta_2,\cdots,\theta_n$ is also the predictive distribution of $\theta_{n+1}$. The sequence of predictive distribution \ref{eqa:dppos} for $\theta_1,\theta_2,\cdots,\theta_n$ is very important and different interpretations on it indicate different properties of the result. To better understand it, we will introduce the most famous three representations of \ref{eqa:dppos}: \textbf{P\'{o}lya urn, Chinese Restaurant Process, Stick-breaking Process}.
\begin{itemize}
	\item \textbf{P\'{o}lya urn} \\
	In this analogy, suppose we are drawing colored balls from an urn, $\theta_i$ represents the color of the $i$-th ball drawn . For each ball drawn, we place it back  and add another one in the same color into the urn. In  the beginning, we pick a color drawn from $H$, paint a ball with that color and drop it into the urn. In the following $n$th step, we will either, pick a new color with probability$\frac{\alpha}{\alpha+n}$, or with probability $\frac{n}{\alpha+n}$ pick a random ball out of the urn.  This process induces a "rich get richer" property on the frequencies of colors inside the urn. Also, it should be noticed that the predictive distribution has point masses located at the previous draws  $\theta_1,\theta_2,\cdots,\theta_n$. Thus the distribution $G$ itself has point masses. When sample size grows larger, the value of any draw will be repeated by another draw, implying that $G$ is composed only of a weighted sum of point masses and thus  it is a discrete distribution.
	\item \textbf{Chinese Restaurant Process}\\
	Another representation of Dirichlet Process-Chinese Restaurant Process(CRP) implies a clustering property. Equation \ref{eqa:dppos} could be rewrite as :
	\begin{equation}
		p(\theta_{N+1}|\theta_1,\theta_2,\cdots,\theta_n) = \frac{1}{\alpha+n}\left(\alpha H+\sum\limits_{i=1}^{n}n_k\delta_{\theta_i^\star}\right)
	\end{equation}
	where $\theta_i^\star$ is the unique values among $\theta_1,\theta_2,\cdots,\theta_n$, and $n_k$ is the number of repeats of $\theta_i^\star$. $\theta_i^\star$ will be repeated by $\theta_{n+1}$ with probability proportional to $n_k$. The larger $n_k$ is, the hight the probability that it will grow. This is similar to the "rich get richer" scheme in \textbf{P\'{o}lya urn}, where large clusters grow larger. We can see that the unique values  of $\theta_1,\theta_2,\cdots,\theta_n$ induce a partitioning of the set $[n]=\{1,2,\cdots,n\}$ into clusters such that within some cluster $k$, the $\theta_i$'s take on the same value $\theta_k^\star$. The random partion encapsulates all the properties of the DP. If we invert the generative process, we can reconstruct the joint distribution over $\theta_1,\theta_2,\cdots,\theta_n$ by first drawin ga random partion on $[n]$, then each cluster $k$in the partition draw a $\theta_k^\star\sim H$, and finally assign $\theta_i=\theta_k^\star$ for each $i$ in cluster $k$. 
	
	The distribution over partitions is called the Chinese Restaurant Process(CRP) in which we have a Chinese restaurant with infinite tables, each of which can seat an infinite number of customers. The first customer enters the restaurant and sits at the first table. And in the following, when the $n+1$th customer comes, he will either joins a tale $k$ with probability propotional to the number $n_k$ of people already sitting there or sts at a new table with probability propotional to $\alpha$. The CRP define a distribution over partitions of $[n]$ and a distribution over permutations of $[n]$. 
	\item \textbf{Stick-breaking Construction} 
	The  third representation of DP is very intuitive and the most widely used one to generate a sample from it. By knowing the fact that draws from a DP consists actually of a weighted sum of point masses, ...provides a constructive and straightforward definition of the DP. It simply following the flowwin steps.
	\begin{eqnarray}
		\beta_k\sim Beta(1,\alpha)&\quad&\theta_k^\star\sim H\nonumber \\
		\pi_k=\beta_k\prod_{l=1}^{k-1}(1-\beta_k)&\quad&G=\sum_{k=1}^{\infty}\pi_k\delta_k^\star
	\end{eqnarray}
	Then we have $G\sim DP(\alpha,H)$. The construction of $\pi$ could be interpreted as breaking a stick of length 1 step by step. First break it at $\beta_1$, assigning $\pi_1$ to be the length of segment we just got. Then recursively breaking the remaining portion to obtain $\pi_2,\pi_3,\cdots,\pi_{n-1}$. THis is a very straightforward and simple procedure.
\end{itemize}   

\subsubsection{ Dirichlet Process Mixture Models}\label{bnp}
In this section, we will briefly describe the Dirichlet Process Mixture Model
Most machine learning problem is targeted to learn a set of parameters describing the model from training data set. This sort of learning is often evaluated in two terms, with the first one being how well the model fits the data, expressed as accuracy or squared error, and the second one being a complexity penalty(favoring simpler models)\cite{gershma2012tutorial,escobar1995bayesian}, also referred to as Ocam's Razor. In practical problem, the model complexity is hard to evaluate. Improper model complexity will lead to over-fitting or under-fi tting\cite{gershman2012tutorial,muller2004nonparametric}, which will then affect the model generalization, i.e to be applied to practical use. Although through rigid training, desirable models could be trained but this is basically a trial and error process\cite{hjort2010bayesian}. That is the movivation of discovering adaptive model complexity selection methods, among which Bayesian Nonparametric Method is the most widely used.

DP, as the most widely used methods among Bayesian Nonparametric Models, has found applications in  both statistics and machine learning, including Bayesian model validation, density estimation and clustering via  mixture models, among which the last one is the most salient  when talking about DP. 

Model validation is to evaluate whether a model gives a good fit to observed data. Under Bayesian approach, we would usually compute the marginal probability of the data under  the model  and compare the  marginal probability to that of other candidate model. The one with the highest probability will be chosen as the best fitting to the observed data. Here arises an issue that how to choose the models to be compared. Usually, a set of candidate models as large as possible would be desirable. But it would be easier if we re-think this in a Bayesian Nonparametric way, i.e. to use the space of all possible distribution as our comparison class, with a prior over distributions. The DP is always the first priority for its similar nature to this problem. The approach is to use the given parametric model as the base distribution of the DP, with DP serving as a nonparametric relaxation around this parametric model. If the parametric model performs as well or better than the DP relaxed model, we are convinced that the model is valid.

For density estimation, the aim is to modeling the latent density from which the observed data is drawn. To avoid the poor performance caused by the limitation in parametric model, we again employ a Nonparametric prior over all densities. If we drawn samples from a DP, which is  distribution over distribution, we will obtain a random distribution which is discrete,thus has no densities. The solution is to smooth out draws form the DP with a kernel. Let $G\sim DP(\alpha,H)$ and $f(x|\theta)$ be a family of densities indexed by $\theta$. Then 
\begin{equation}
	p(x)=\int f(x|\theta)G(\theta)d\theta
\end{equation}

The most common application of the Dirichlet process is to cluster data using mixture  models. The traditional finite mixture model assumes that there are $K$ clusters, each associated with a parameter $\theta_k$. Each observation $y_n$ is assumed to be generated by first  choosing a sluster $c_n$ according to $P(c_n)$ and then generating the observation from its corresponding observation destribution parameterized by $\theta_{c_n}$. Finite model can accomodate many kinds of data by changing the data generating distribution.

Bayesian mixture models further contain a prior over the mixing distributions. The nature of Dirichlet process will translate the mixing model to a countably infinite number of components. we model a set of observations $\{x_1,\cdots,x_n\}$ using a set of latent parameters  $\{\theta_1,\cdots,\theta_n\}$, each $\theta_i$ is drawn I.I.d from $G$, while each $x_i$ has distribution $F(\theta_i)$ parameterized by $\theta_i$:
\begin{eqnarray}
	x_i|\theta_i&\sim& F(\theta_i)\nonumber\\
	\theta_i|G&\sim& G\\
	G|\alpha,H&\sim& DP(\alpha,H)\nonumber \label{eqa:DPM}
\end{eqnarray}
Because $G$ is discrete, multiple $\theta_i$'s can take on the same value simultaneously, and the model above can be seen as a mixture model, where $x_i$'s with the same value of $\theta_i$ belong to the same cluster. The mixture perspective can be made more in agreement with the usual representation of mixture models using the stick-breaking construction. Let $z_i$ be a cluster assignment variable, which takes on value $k$ with probability $\pi_k$. Then equation \ref{eqa:DPM} could be expressed as:
\begin{eqnarray}
	\pi|\alpha\sim GEM(\alpha)& \quad &\theta_k^\star|H\sim H \nonumber \\
	z_i|\pi\sim  Mult(\pi)& \quad & x_i|z_i,\{\theta_k^\star\} \sim F(\theta_{z_i}^\star)
\end{eqnarray}
with $G=\sum\nolimits_{k=1}^\infty\pi_k\delta_{\theta_k^\star}$,  $\theta_i=\theta_{z_i}^\star$, $\pi$ being the mixing proportion, $\theta_k^\star$ being the cluster parameters, $F(\theta_k^\star)$ being the distribution over data in cluster $k$ and $H$ the prior over cluster parameters.

From above expression, it is seen that DP mixture model is an infinite mixture model-a mixture model with a countably infinite number of clusters. Different from finite mixture model using a fixed number of clusters, $\pi_k$'s decrease exponentially quickly, and only a small number of clusters will be used to model the data a priori. In the DP mixture model, the actual number of clusters used to model data is not fixed, and can be automatically inferred from data using the usual Bayesian posterior inference framework. The equivalent operation for finite mixture models would be model averaging or model selection for the appropriate number of components.
\\
\begin{table}[!htbp]
\caption{Equivalences between different descriptions of the Dirichlet Process}
\centering
\begin{tabular*}{\textwidth}{|c|c|c|}
	\hline \rule[-2ex]{0pt}{5.5ex}  & \textbf{Indexing}& \textbf{Partition Labels} \\ 
	\hline \rule[-2ex]{0pt}{5.5ex}  \textbf{P\'{o}lya Urn} & sequence of draws of balls  & ball colors  \\ 
	\hline \rule[-2ex]{0pt}{5.5ex} \textbf{Chinese Restaurant Process} & sequence of incoming customers &  different dishes\\ 
	\hline \rule[-2ex]{0pt}{5.5ex}  \textbf{Clustering} & sequence of the natural numbers  & clusters \\ 
	\hline 
	\title{}
\end{tabular*}
\end{table}

	\subsection{Inference}
	We have described three different representations of Dirichlet Process, and all of them posit a generative probabilistic process of a collection of observed (and future) data that includes hidden structure. And the observed data is analyzed by examining the posterior distribution of the hidden structure given the observations; this
	gives us a distribution over which latent structure likely generated our data. 
	
	Thus, the basic computational problem in DP modeling (as in most of Bayesian statistics) is computing the posterior. Unfortunately, for many models posterior is not available in closed form. But there are several ways to approximate it. The most widely used posterior inference methods in Bayesian nonparametric models are
	Markov Chain Monte Carlo (MCMC) methods. The idea MCMC methods is to define a Markov chain on the hidden variables that has the posterior as its equilibrium distribution \cite{Andrieu2003}. By drawing samples from this Markov chain, one eventually obtains samples from the posterior. A simple form of MCMC sampling is Gibbs sampling, where the Markov chain is constructed by considering the conditional distribution of each hidden variable given the others and the observations. CRP mixtures are
	particularly amenable to Gibbs sampling due to the exchangability property, and each observation can be considered to be the "last" one and the distribution of Equation \ref{fig:DPsample} can be used as one term of the conditional distribution. \cite{Andrieu2003} provides an excellent survey of Gibbs sampling and other MCMC
	algorithms for inference in CRP mixture models.
	
	An alternative approach to approximating the posterior is variational inference \cite{Jordan1999}. This approach is based on the idea of approximating the posterior with a simpler family of distributions and searching for the member of that family that
	is closest to it. Although variational methods are not guaranteed to recover the true posterior (unless it belongs to the simple family of distributions), they are typically faster than MCMC \cite{Blei2006}and convergence assessment is straightforward. These methods have been applied to CRP mixture
	models. 
	
	Both MCMC and variational strategies for posterior inference provide a data-directed mechanism for simultaneously searching the space of models and finding optimal parameters. This is convenient  mixture modeling because we avoid needing updating on models for each candidate number of components. It is essential in more complex settings where the algorithm searches over a space that is diffcult to effciently enumerate and explore. In this research, we will focus on the MCMC algorithm on Dirichlet Process.
	\subsubsection{Variational Inference}\label{vi}
	Variational Inference Methods have been introduced for the inference of DP in \cite{Blei2006}. Under this scheme, variational methods approximate a posterior distribution $p(\theta|X)$ with a distribution $q(\theta)$  belonging to a more manageable family of distributions and try to find the best approximation, usually by minimizing the \textit{Kullback-Leibler} divergence between $p(\theta|X)$ and $q(\theta)$. 
	\begin{equation}
		KL(q||p)=E_q\frac{q(\theta)}{p(\theta)}
	\end{equation}
	Then the desired $q$ could be formulated as an optimazation problem:
	\begin{equation}
		q^\star=\argmin{q\in Q} KL(q(\theta)||p(\theta|X))
	\end{equation}
	
	
	The variational inference framework gives a principled way of finding an approximate distribution which is as close (as measured by KL)
	to the posterior. This will allow us to tackle posterior computations for models such as mixtures.
	
	A typical approach to selecting the family fo approximation distributions is to assume independencies that may not be present in the true posterior. The quality of the approximation depends on $Q$: the bigger the $Q$, the better. Two of the familiar classical
	algorithms (hard EM and EM) are based on a particular kind of $Q$. The assumption will allow the possibility of parallelization. However, the assumptions constrains the posterior distribution in a restricted class of models, thus the expressiveness of true model might be lost leading to a less accurate results.
	\subsubsection{Markov Chain Monte Carlo Sampling}
	One method for sampling from an arbitrary target distribution is to use a Markov chain Monte Carlo (MCMC) algorithm. MCMC methods simulate a Markov chain with a particular transition distribution such that the stationary distribution of the chain is exactly the target distribution of interest. Certain conditions must be specified to ensure that this condition holds. A sample from the target distribution can then be generated by simulating a Markov chain until it converges to its stationary distribution, followed by taking the value of the chain when it is terminated. 
	
	The state of a Markov chain at iteration $t$ is denoted as $z^t$. Suppose that the Markov chain evolves according to some transition distribution,$q^{\star}(z^{(t+1)}|z^{(t)})$. A stationary distribution of a Markov chain is a distribution over states that is invariant under the transition distribution $q^\star$. A distribution is the stationary distribution of a Markov Chain if it satisfies
	\begin{equation}
	f_z(z^{(t+1)})=\int f_z(z^{(t)})q^{\star}(z^{(t+1)}|z^{(t)})dz^{(t)}
	\end{equation}
	Stationarity of a Markov chain with respect to a transition distribution essentially means that if the chain is currently in the stationary distribution, simulating a transition from $q^\star$ will not alter the distribution. 
	
	Multiple such distribution can exist for a Markov chain. MCMC sampling algorithms must consequently ensure uniqueness by enforcing \textit{ergodicity} of the Markov chain, i.e. the Markov chain must satisfy the condition of being \textit{irreducible and aperiodic}. An ergodic Markov chains will converge to a unique stationary distribution regardless of the initial state.
	\begin{itemize}
		\item \textbf{Metropolis-Hasting Sampling}\\
		The idea of MCMC sampling is to simulate a Markov chain that has the target distribution as a stationary distribution. Different from the Variational Inference methods introduced in\ref{vi}, MCMC methods sampls from the true posterior distribution asymptotically. Ergodicity ensures convergence to the chain, but one has to use additional methodologies to ensure the correct stationary distribution. The Metropolis-Hastings algorithm is one such method.
		It is supposed that there is a proposal distribution $p(z^{(t+1)}|z^{(t)})$ from which we can sampling candidate state. Metropolis et al.\cite{Metropolis1953} developed an algorithm that constructs a transition distribution, $q\star$, from a symmetric proposal distribution, $p$, such that the stationary distribution is exactly the target distribution. Hastings\cite{Hastings1970} later generalized this algorithm to allow for non-symmetric proposal distributions. The latter algorithm is commonly referred to as the Metropolis-Hastings (MH) algorithm. The concept underlying the MH algorithm the the notion of \textit{detailed balance} which shows that if a Markov chain is constructed with a transition distribution, $q$, that satisfies 
		\begin{equation}
			f_z(z_1)q(z_2|z_1)=f_z(z_2)q(z_1|z_2)
		\end{equation}
		then the chain is said to satisfy the detailed balance condition. Furthermore,  $f_z(z)$ is
		guaranteed to be a stationary distribution of the chain. Detailed balance is a sufficient condition to ensure that  $f_z(z)$ is a stationary distribution, but it is not necessary. Once we get the candidate new state from the proposal distribution $p$, MH algorithm shows that if the transition distribution $q^\star$ is constructed according to
		\begin{equation}
			q^{\star}(z^{(t+1)}|z^{(t)})=min[1,\frac{f(z^{(t+1)})}{f{(z^(t)})}\frac{q(z^(t)|z^{(t+1)})}{q(z^{(t+1)}|z^{(t)})}]
		\end{equation}
		then the resulting Markov chain satisfies the detailed balance condition. The constructed transition distribution subjects the newly proposed sample to an accept or reject step.
		The Metropolis-Hastings algorithm therefore guarantees that the target distribution is a stationary distribution of the chain. Furthermore, Markov chain theory states that the resulting Markov chain is guaranteed to converge uniquely to the stationary distribution if it is ergodic.
		\item \textbf{Gibbs Sampling}
		 Gibbs sampling [40] is a special case of Metropolis-Hastings where the transition distribution only acts on a subset of the variables (or, a subset of dimensions of a multidimensional variable). In particular, the Gibbs sampler chooses the proposal distribution to be the true posterior distribution of the subset of variables conditioned on all variables. Gibbs sampling precludes the need of an accept/reject step because it results in a Hastings ratio that evaluates to 1, i.e. the Gibbs sampling algorithm can accept all proposed samples while still satisfying detailed balance. 
		 
		 Gibbs sampling is often preferred over Metropolis-Hastings because it does not re-
		 quire one to specify a proposal distribution. However, it can only be used when the
		 conditional posterior distributions are known. Furthermore, Gibbs sampling may result in slow convergence because only a single random dimension of the latent variable is sampled at a time. This procedure can explore the space very slowly due to the local changes proposed by the sampling algorithm.
		 
	\end{itemize}
	
	\subsection{Markov Chain Monte Carlo for DPMM}
	 DPMM as widely used in the the industrial and reserch area of machine learning as the model allow for an automatic model selection in clustering problem, one of the basic yet important procudure of data mining. As can be seen from previous chapter, despite the powerful representation of the model, the infinite and unlimited component number make it hard to represent them explicitly, leading to work on developing methods of posterior inference. . 
	 
	 The most widely used methods in posterior inference in DPMM is to draw samples of those latent variables using a Markov Chain Monte Carlo scheme. But posterior sampling in such complex models using MCMC is often difficult because samplers proposing local changes exhibit poor convergence. To address the convergence problem, many algorithms are poposed. In this section, a brief introduction to those methods will be given.
	 \begin{itemize}
	 	\item \textbf{Gibbs Sampling based on P\'{o}lya urn} \\
	 	In the P\'{o}lya urn representation of DPMM (\ref{eqa:DPM}) as shown in figure
	 \end{itemize}
	\subsection{Summary}
	
	In this section, we briefly reviewed the basics in Dirichlet process, including their three different representations-P\'{o}lya urn, Chinese Restaurant Process and Stick-breaking Process, and each one shows the different properties of Dirichlet Process. Also, we delve into the inference strategies of Dirichlet Process, including Markov Chain Monte Carlo and Variational Inference. 
   
    Generally, Dirichlet Process, as the most representative modeling in Bayesian Nonparametric analysis, are an emerging trend for buildin gflexible models whose strcture grows and adapts to data. But the easy and flexible modeling procedure does not guaranteen a relaxed inference procedure especially when the data set grows larger. Thus, the poposal is mainly focus on the inference procedure, aiming at developing a more efficient mechenism to inference.  